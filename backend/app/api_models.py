"""
Endpoint para detectar modelos disponibles en una API
"""
import httpx
from typing import List, Dict, Any, Optional

# Descripciones de para quÃ© es buena cada IA
MODEL_DESCRIPTIONS = {
    # OpenAI
    "gpt-4o": "ğŸ§  Mejor para: Razonamiento complejo, anÃ¡lisis profundo, cÃ³digo avanzado",
    "gpt-4o-mini": "âš¡ Mejor para: Tareas rÃ¡pidas, chat, resÃºmenes, bajo costo",
    "gpt-4-turbo": "ğŸ’ª Mejor para: Tareas largas, documentos extensos, visiÃ³n",
    "gpt-3.5-turbo": "ğŸ’° Mejor para: Tareas simples, alto volumen, econÃ³mico",
    "o1-preview": "ğŸ”¬ Mejor para: MatemÃ¡ticas, ciencia, razonamiento paso a paso",
    "o1-mini": "ğŸ§® Mejor para: CÃ³digo, lÃ³gica, problemas tÃ©cnicos",
    
    # Groq (Llama)
    "llama-3.3-70b-versatile": "ğŸ¦™ Mejor para: Uso general, rÃ¡pido, multilingÃ¼e",
    "llama-3.1-70b-versatile": "ğŸ¦™ Mejor para: Razonamiento, cÃ³digo, anÃ¡lisis",
    "llama-3.1-8b-instant": "âš¡ Mejor para: Respuestas ultra rÃ¡pidas, chat",
    "llama-guard-3-8b": "ğŸ›¡ï¸ Mejor para: ModeraciÃ³n de contenido, seguridad",
    "mixtral-8x7b-32768": "ğŸ­ Mejor para: Contexto largo, multilingÃ¼e",
    "gemma-7b-it": "ğŸ’ Mejor para: Instrucciones, tareas especÃ­ficas",
    "gemma2-9b-it": "ğŸ’ Mejor para: Razonamiento mejorado, cÃ³digo",
    
    # DeepSeek
    "deepseek-chat": "ğŸ” Mejor para: Chat general, cÃ³digo, anÃ¡lisis",
    "deepseek-coder": "ğŸ’» Mejor para: ProgramaciÃ³n, debugging, cÃ³digo",
    "deepseek-reasoner": "ğŸ§  Mejor para: Razonamiento profundo, matemÃ¡ticas",
    
    # Anthropic Claude
    "claude-3-5-sonnet-20241022": "âœ¨ Mejor para: Escritura, anÃ¡lisis, cÃ³digo elegante",
    "claude-3-opus-20240229": "ğŸ‘‘ Mejor para: Tareas complejas, creatividad, investigaciÃ³n",
    "claude-3-sonnet-20240229": "ğŸ“ Mejor para: Balance calidad/velocidad, documentos",
    "claude-3-haiku-20240307": "ğŸš€ Mejor para: Respuestas rÃ¡pidas, alto volumen",
    
    # Mistral
    "mistral-large-latest": "ğŸŒŸ Mejor para: Razonamiento, multilingÃ¼e europeo",
    "mistral-medium-latest": "âš–ï¸ Mejor para: Balance costo/rendimiento",
    "mistral-small-latest": "ğŸ’¨ Mejor para: Tareas simples, rÃ¡pido",
    "codestral-latest": "ğŸ’» Mejor para: CÃ³digo, 80+ lenguajes",
    
    # Together AI
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": "ğŸ¦™ Mejor para: Instrucciones, chat, anÃ¡lisis",
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": "ğŸ† Mejor para: MÃ¡xima calidad, tareas complejas",
    "mistralai/Mixtral-8x22B-Instruct-v0.1": "ğŸ­ Mejor para: Contexto largo, multilingÃ¼e",
    "Qwen/Qwen2.5-72B-Instruct-Turbo": "ğŸ‰ Mejor para: Chino/inglÃ©s, cÃ³digo, matemÃ¡ticas",
    
    # OpenRouter
    "openai/gpt-4o": "ğŸ§  Mejor para: Razonamiento complejo, anÃ¡lisis",
    "anthropic/claude-3.5-sonnet": "âœ¨ Mejor para: Escritura, cÃ³digo elegante",
    "google/gemini-pro-1.5": "ğŸŒ Mejor para: Multimodal, contexto muy largo",
    "meta-llama/llama-3.1-405b-instruct": "ğŸ† Mejor para: Open source mÃ¡s potente",
}


async def fetch_available_models(api_type: str, api_key: str, base_url: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    Consulta la API para obtener los modelos disponibles.
    Retorna lista de modelos con nombre y descripciÃ³n.
    """
    # Endpoints por proveedor
    endpoints = {
        "openai": "https://api.openai.com/v1/models",
        "groq": "https://api.groq.com/openai/v1/models",
        "deepseek": "https://api.deepseek.com/v1/models",
        "together": "https://api.together.xyz/v1/models",
        "openrouter": "https://openrouter.ai/api/v1/models",
        "mistral": "https://api.mistral.ai/v1/models",
        "ollama": "http://localhost:11434/v1/models",
    }
    
    url = base_url or endpoints.get(api_type, endpoints["openai"])
    if not url.endswith("/models"):
        url = url.rstrip("/") + "/models"
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            headers = {"Authorization": f"Bearer {api_key}"}
            response = await client.get(url, headers=headers)
            
            if response.status_code != 200:
                return []
            
            data = response.json()
            models_data = data.get("data", data.get("models", []))
            
            models = []
            for model in models_data:
                model_id = model.get("id", model.get("name", ""))
                if not model_id:
                    continue
                    
                # Filtrar solo modelos de chat/completions
                if any(skip in model_id.lower() for skip in ["embed", "whisper", "tts", "dall-e", "moderation"]):
                    continue
                
                description = MODEL_DESCRIPTIONS.get(model_id, "ğŸ¤– Modelo de IA")
                
                models.append({
                    "id": model_id,
                    "name": model_id,
                    "description": description,
                    "provider": api_type,
                })
            
            # Ordenar por nombre
            models.sort(key=lambda x: x["name"])
            return models
            
    except Exception as e:
        print(f"Error fetching models: {e}")
        return []


def get_model_description(model_id: str) -> str:
    """Obtiene la descripciÃ³n de un modelo."""
    return MODEL_DESCRIPTIONS.get(model_id, "ğŸ¤– Modelo de IA para tareas generales")
